# By default, this will use your Nvidia GPU, comment this out to use CPU only
COMPOSE_FILE=docker-compose.yml:docker-compose.gpu.yml
# To use the paid OpenAI Whisper API instead of running the model locally
# COMPOSE_FILE=docker-compose.yml:docker-compose.openai.yml

# To use MinIO and save files locally instead of signing up for S3, add :docker-compose.minio.yml to your COMPOSE_FILE env

# Which Dockerfile to use for building the worker
# Dockerfile.whisper if you want the original Whisper, Dockerfile.fasterwhisper for Faster Whisper, Dockerfile.whispercpp for Whisper.cpp
# WORKER_DOCKERFILE=Dockerfile.whispercpp

# Whisper model to use, choose from small.en, medium.en, large-v2
# By default, small.en will be used
# To use the OpenAI API, comment this out
WHISPER_MODEL=small.en

# Desired CUDA version to use (as well as some special options).
# Available options:
# cu117 - CUDA 11.7
# fw - Faster Whisper on the GPU
# cpu-cpp - Whisper.cpp on the CPU
# cpu-fw - Faster Whisper on the CPU
# cpu - regular Whisper on the CPU
#
# By default, cu117 will be used for the GPU, and cpu-cpp for the CPU
DESIRED_CUDA=cu117

# OpenAI API key, if using the paid Whisper API (and comment out the WHISPER_MODEL line above)
# OPENAI_API_KEY=

#
# Queue settings
#

# CELERY_LOGLEVEL=debug
CELERY_BROKER_URL=amqp://rabbitmq:5672
CELERY_RESULT_BACKEND=rpc://rabbitmq:5672
# CELERY_CONCURRENCY=1

FLOWER_BROKER_API=http://rabbitmq:15672/api/

# To set auth on RabbitMQ (update URLs above if so, in the form user:pass@rabbitmq)
# RABBITMQ_DEFAULT_USER=
# RABBITMQ_DEFAULT_PASS=

#
# Database settings
#

# Uncomment the following to save calls to a database - will be required in future versions
# POSTGRES_HOST=postgres
# POSTGRES_USER=postgres
# POSTGRES_PASSWORD=changeme
# POSTGRES_DB=trunk_transcribe

#
# API settings
#

# This should be a publicly-accessible URL to the API server, from whever the worker is being run
API_BASE_URL=http://api:8000
API_KEY=testing

#
# Search settings
#

# Version of Meilisearch to use (e.g. v1.4.0)
# MEILI_VERSION=

MEILI_MASTER_KEY=testing
MEILI_URL=http://meilisearch:7700
# To use a different index name other than calls:
# MEILI_INDEX=calls
# For large systems, to make a new index for each month (e.g. calls_2024_01); MEILI_INDEX becomes the prefix
# MEILI_INDEX_SPLIT_BY_MONTH=true

#
# Storage settings
#

# These settings are for an S3 bucket that will contain call audio, so it can be played back later as part of search.

# S3_BUCKET=my-bucket
# S3_PUBLIC_URL=https://my-bucket.s3.us-east-1.amazonaws.com
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=

# If using a different location than us-east-1 or a provider with an S3-compatible API
# S3_ENDPOINT=

# To use MinIO and save files locally instead of signing up for S3, uncomment this section instead
# S3_BUCKET=trunk-transcribe
# The S3 public URL should be the publicly-accessible IP or domain of the MinIO server, with the port and bucket name
# S3_PUBLIC_URL=http://minio:9000/trunk-transcribe
# AWS_ACCESS_KEY_ID=changeme
# AWS_SECRET_ACCESS_KEY=changeme
# S3_ENDPOINT=http://minio:9000

#
# Notification settings
#

# These values are in seconds
# DELAYED_CALL_THRESHOLD=120
# MAX_CALL_AGE=1200

#
# Third party service settings
#

# TELEGRAM_BOT_TOKEN=

# OPENAI_API_KEY=

# GOOGLE_GEMINI_API_KEY=

# GOOGLE_MAPS_API_KEY=

# GEOCODIO_API_KEY=
# ARCGIS_USERNAME=
# ARCGIS_PASSWORD=

# GEOCODING_BOUNDS="41.6,-87.9|42,-87.5"
# GEOCODING_CITY=Chicago
# GEOCODING_STATE=IL
# GEOCODING_COUNTRY=US
# GEOCODING_ENABLED_SYSTEMS="system1,system2"

# SENTRY_DSN=

# BCFY_USER=
# BCFY_PASS=
