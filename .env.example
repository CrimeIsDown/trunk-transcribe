# There are a variety of Docker Compose files that can be used to run the API and worker.
# docker-compose.server.yml - API server, RabbitMQ, Meilisearch
# docker-compose.minio.yml - MinIO (S3) server for local file storage
# docker-compose.worker.yml - Main queue worker
# docker-compose.whisper.yml - CPU only self hosted Whisper worker
# docker-compose.gpu.yml - Self hosted Whisper worker with Nvidia GPU support
# docker-compose.autoscaler.yml - Autoscaler when using vast.ai to run workers

# By default, this will run a self-contained setup, with the neccessary servers, worker, and GPU support
# NOTE: On Windows, use ; to separate the files instead of :
COMPOSE_FILE=docker-compose.server.yml:docker-compose.worker.yml:docker-compose.whisper.yml:docker-compose.gpu.yml:docker-compose.minio.yml

# Whisper model to use, choose from small.en, medium.en, large-v2, large-v3, large-v3-turbo
# By default, small.en will be used
# For Deepgram, you can choose from the models on https://developers.deepgram.com/docs/model
WHISPER_MODEL=small.en

# Whisper implementation to use
# By default, the original Whisper will be used
# Available options:
# - whisper (https://github.com/openai/whisper)
# - faster-whisper (https://github.com/SYSTRAN/faster-whisper)
# - whisper.cpp (https://github.com/ggerganov/whisper.cpp)
# - whispers2t (https://github.com/shashikg/WhisperS2T)
# - openai (OpenAI API)
# - deepgram (Deepgram speech-to-text API, Nova 2 model)
# - deepinfra (DeepInfra OpenAI-compatible speech-to-text API)
WHISPER_IMPLEMENTATION=whisper

# Which Dockerfile to use for building the worker
# Available options:
# Dockerfile.whisper (https://github.com/openai/whisper)
# Dockerfile.fasterwhisper (https://github.com/SYSTRAN/faster-whisper)
# Dockerfile.whispercpp (https://github.com/ggerganov/whisper.cpp)
# Dockerfile.whispers2t (https://github.com/shashikg/WhisperS2T)
WORKER_DOCKERFILE=Dockerfile.whisper

# Desired CUDA version to use (as well as some special options).
# Available options:
# 12.3.2 - CUDA 12.3 (required for faster-whisper)
# 12.1.0 - CUDA 12.1 (default for Whisper on the GPU)
# cpu - regular Whisper on the CPU
#
# By default, 12.1.0 will be used for the GPU, and cpu for the CPU
# Note: if you have a newer CUDA version installed on your system, still use 12.1.0 here
CUDA_VERSION=12.1.0

# OpenAI API key, if using the paid Whisper API (and switch your WHISPER_IMPLEMENTATION to openai)
# OPENAI_API_KEY=

# Deepgram API key, if using the Deepgram transcription API (and switch your WHISPER_IMPLEMENTATION to deepgram)
# DEEPGRAM_API_KEY=

# DeepInfra API key, if using the DeepInfra transcription API (and switch your WHISPER_IMPLEMENTATION to deepinfra)
# DEEPINFRA_API_KEY=
# Optional override for DeepInfra base URL
# DEEPINFRA_BASE_URL=https://api.deepinfra.com/v1/openai

#
# Queue settings
#

# CELERY_LOGLEVEL=debug
CELERY_BROKER_URL=amqp://rabbitmq:5672
CELERY_RESULT_BACKEND=rpc://rabbitmq:5672
# CELERY_CONCURRENCY=1
# This multiplier should be 0 if using batching
# CELERY_PREFETCH_MULTIPLIER=1

FLOWER_BROKER_API=http://rabbitmq:15672/api/

# To set auth on RabbitMQ (update URLs above if so, in the form user:pass@rabbitmq)
# RABBITMQ_DEFAULT_USER=
# RABBITMQ_DEFAULT_PASS=

#
# Database settings
#

POSTGRES_HOST=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changeme
POSTGRES_DB=trunk_transcribe

#
# API settings
#

# This should be a publicly-accessible URL to the API server, from whever the worker is being run
API_BASE_URL=http://api:8000
API_KEY=testing

#
# Search settings
#

# Version of Meilisearch to use (e.g. v1.4.0)
# MEILI_VERSION=

# MEILI_MASTER_KEY=testing
# MEILI_URL=http://meilisearch:7700
# To use a different index name other than calls:
# MEILI_INDEX=calls
# For large systems, to make a new index for each month (e.g. calls_2024_01); MEILI_INDEX becomes the prefix
# MEILI_INDEX_SPLIT_BY_MONTH=true

# Version of Typesense to use
TYPESENSE_VERSION=27.1

TYPESENSE_API_KEY=testing
TYPESENSE_URL=http://typesense:8108

SEARCH_UI_URL=http://localhost:3000

#
# Storage settings
#

# These settings are for an S3 bucket that will contain call audio, so it can be played back later as part of search.

# S3_BUCKET=my-bucket
# S3_PUBLIC_URL=https://my-bucket.s3.us-east-1.amazonaws.com
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=

# If using a different location than us-east-1 or a provider with an S3-compatible API
# S3_ENDPOINT=

# To use MinIO and save files locally instead of signing up for S3, uncomment this section instead
S3_BUCKET=trunk-transcribe
# The S3 public URL should be the publicly-accessible IP or domain of the MinIO server, with the port and bucket name
S3_PUBLIC_URL=http://127.0.0.1:9000/trunk-transcribe
AWS_ACCESS_KEY_ID=changeme
AWS_SECRET_ACCESS_KEY=changeme
S3_ENDPOINT=http://minio:9000

#
# Notification settings
#

# These values are in seconds
# DELAYED_CALL_THRESHOLD=120
# MAX_CALL_AGE=1200

#
# Third party service settings
#

# TELEGRAM_BOT_TOKEN=

# OPENAI_API_KEY=

# GOOGLE_GEMINI_API_KEY=

# GOOGLE_MAPS_API_KEY=
# MAPBOX_API_KEY=
# GEOCODIO_API_KEY=
# GEOAPIFY_API_KEY=
# ARCGIS_USERNAME=
# ARCGIS_PASSWORD=

# GEOCODING_SERVICE=
# GEOCODING_BOUNDS="41.6,-87.9|42,-87.5"
# GEOCODING_CITY=Chicago
# GEOCODING_STATE=IL
# GEOCODING_COUNTRY=US
# GEOCODING_ENABLED_SYSTEMS="system1,system2"

# SENTRY_DSN=

# BCFY_USER=
# BCFY_PASS=
