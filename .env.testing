# There are a variety of Docker Compose files that can be used to run the API and worker.
# docker-compose.server.yml - API server, RabbitMQ, Meilisearch
# docker-compose.minio.yml - MinIO (S3) server for local file storage
# docker-compose.worker.yml - Transcription Worker
# docker-compose.gpu.yml - Nvidia GPU support for the worker
# docker-compose.openai.yml - OpenAI API support for the worker
# docker-compose.autoscaler.yml - Autoscaler when using vast.ai to run workers

# By default, this will run a self-contained setup, with the neccessary servers, worker, and GPU support
# NOTE: On Windows, use ; to separate the files instead of :
COMPOSE_FILE=docker-compose.server.yml:docker-compose.worker.yml:docker-compose.minio.yml

# Whisper model to use, choose from small.en, medium.en, large-v2, large-v3
# By default, small.en will be used
# For Deepgram, you can choose from the models on https://developers.deepgram.com/docs/model
WHISPER_MODEL=small.en

# Whisper implementation to use
# By default, the original Whisper will be used
# Available options:
# - whisper (https://github.com/openai/whisper)
# - faster-whisper (https://github.com/SYSTRAN/faster-whisper)
# - whisper.cpp (https://github.com/ggerganov/whisper.cpp)
# - whispers2t (https://github.com/shashikg/WhisperS2T)
# - openai (OpenAI API)
# - deepgram (Deepgram speech-to-text API, Nova 2 model)
WHISPER_IMPLEMENTATION=openai

# Which Dockerfile to use for building the worker
# Available options:
# Dockerfile.whisper (https://github.com/openai/whisper)
# Dockerfile.fasterwhisper (https://github.com/SYSTRAN/faster-whisper)
# Dockerfile.whispercpp (https://github.com/ggerganov/whisper.cpp)
# Dockerfile.whispers2t (https://github.com/shashikg/WhisperS2T)
WORKER_DOCKERFILE=Dockerfile.whisper

# Desired CUDA version to use (as well as some special options).
# Available options:
# cu121 - CUDA 12.1 (required for faster-whisper and whispers2t)
# cpu - regular Whisper on the CPU
#
# By default, cu121 will be used for the GPU, and cpu for the CPU
DESIRED_CUDA=cu121

# OpenAI API key, if using the paid Whisper API (and switch your WHISPER_IMPLEMENTATION to openai)
# OPENAI_API_KEY=

#
# Queue settings
#

# CELERY_LOGLEVEL=debug
CELERY_BROKER_URL=amqp://rabbitmq:5672
CELERY_RESULT_BACKEND=rpc://rabbitmq:5672
# CELERY_CONCURRENCY=1

FLOWER_BROKER_API=http://rabbitmq:15672/api/

# To set auth on RabbitMQ (update URLs above if so, in the form user:pass@rabbitmq)
# RABBITMQ_DEFAULT_USER=
# RABBITMQ_DEFAULT_PASS=

#
# Database settings
#

# Uncomment the following to save calls to a database - will be required in future versions
POSTGRES_HOST=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changeme
POSTGRES_DB=trunk_transcribe

#
# API settings
#

# This should be a publicly-accessible URL to the API server, from whever the worker is being run
API_BASE_URL=http://api:8000
API_KEY=testing

#
# Search settings
#

# Version of Meilisearch to use (e.g. v1.4.0)
# MEILI_VERSION=

MEILI_MASTER_KEY=testing
MEILI_URL=http://meilisearch:7700
# To use a different index name other than calls:
# MEILI_INDEX=calls
# For large systems, to make a new index for each month (e.g. calls_2024_01); MEILI_INDEX becomes the prefix
MEILI_INDEX_SPLIT_BY_MONTH=false

#
# Storage settings
#

# These settings are for an S3 bucket that will contain call audio, so it can be played back later as part of search.

# S3_BUCKET=my-bucket
# S3_PUBLIC_URL=https://my-bucket.s3.us-east-1.amazonaws.com
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=

# If using a different location than us-east-1 or a provider with an S3-compatible API
# S3_ENDPOINT=

# To use MinIO and save files locally instead of signing up for S3, uncomment this section instead
S3_BUCKET=trunk-transcribe
# The S3 public URL should be the publicly-accessible IP or domain of the MinIO server, with the port and bucket name
S3_PUBLIC_URL=http://minio:9000/trunk-transcribe
AWS_ACCESS_KEY_ID=changeme
AWS_SECRET_ACCESS_KEY=changeme
S3_ENDPOINT=http://minio:9000

#
# Notification settings
#

# These values are in seconds
DELAYED_CALL_THRESHOLD=120
MAX_CALL_AGE=0

#
# Third party service settings
#

# TELEGRAM_BOT_TOKEN=

# OPENAI_API_KEY=

# GOOGLE_GEMINI_API_KEY=

# GOOGLE_MAPS_API_KEY=
# MAPBOX_API_KEY=
# GEOCODIO_API_KEY=
# ARCGIS_USERNAME=
# ARCGIS_PASSWORD=

GEOCODING_BOUNDS="41.6,-87.9|42,-87.5"
GEOCODING_CITY=Chicago
GEOCODING_STATE=IL
GEOCODING_COUNTRY=US
GEOCODING_ENABLED_SYSTEMS="chi_cpd,chi_cfd,chi_oemc,sc21102"

# SENTRY_DSN=

# BCFY_USER=
# BCFY_PASS=
